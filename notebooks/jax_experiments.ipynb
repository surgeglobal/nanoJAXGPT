{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from helpers.eqx import named_parameters\n",
    "\n",
    "for pn, p in named_parameters(gpt):\n",
    "    print(pn, p.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "temp = jax.random.normal(key, (5,))\n",
    "temp.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "t, = temp.shape\n",
    "t"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "learning_rate = 5e-5\n",
    "b1 = 0.001\n",
    "b2 = 0.005"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_conditional_tree(tree, condition):\n",
    "  \"\"\"Creates a new tree based on a condition applied to leaf nodes.\n",
    "\n",
    "  Args:\n",
    "    tree: The input JAX tree.\n",
    "    condition: A function that takes a leaf node and returns a boolean.\n",
    "\n",
    "  Returns:\n",
    "    A new JAX tree with leaves modified based on the condition.\n",
    "  \"\"\"\n",
    "\n",
    "  def tree_fn(node, **kwargs):\n",
    "    if jax.tree_leaves(tree)[0].ndim > 2:\n",
    "      return False\n",
    "    else:\n",
    "      return True\n",
    "\n",
    "  return jax.tree.map(tree_fn, tree)\n",
    "\n",
    "# Example usage\n",
    "conditional_tree = create_conditional_tree(gpt, lambda x: x.ndim > 2)\n",
    "\n",
    "print(conditional_tree)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from helpers.eqx import named_parameters\n",
    "import optax\n",
    "\n",
    "param_dict = {pn: p for pn, p in named_parameters(gpt)}\n",
    "# create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
    "# i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
    "decay_params = [p for n, p in param_dict.items() if p.ndim >= 2]\n",
    "decay_param_tree = eqx.filter(gpt, lambda l: any([jnp.array_equal(l, x) for x in decay_params]), replace=False)\n",
    "decay_param_tree = eqx.filter(decay_param_tree, lambda l: l is False, replace=True)\n",
    "nodecay_params = [p for n, p in param_dict.items() if p.ndim < 2]\n",
    "\n",
    "num_decay_params = sum(jax.numpy.size(p) for p in decay_params)\n",
    "num_nodecay_params = sum(jax.numpy.size(p) for p in nodecay_params)\n",
    "print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
    "print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
    "# Create AdamW optimizer and use the fused version if it is available\n",
    "\n",
    "optimizer = optax.adamw(learning_rate=learning_rate, b1=b1, b2=b2, weight_decay=1e-1, mask=decay_param_tree)\n",
    "\n",
    "## TODO: MEKA RUN KRLA BALAPAAAAAN"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "source": [
    "from model import GPT, GPTConfig\n",
    "import jax\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "gpt = GPT.create_instance(GPTConfig(), key)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "temp = jax.random.normal(key, (5,))\n",
    "temp.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "learning_rate = 5e-5\n",
    "b1 = 0.001\n",
    "b2 = 0.005"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "from helpers.eqx import named_parameters\n",
    "import optax\n",
    "\n",
    "param_dict = {pn: p for pn, p in named_parameters(gpt)}\n",
    "# create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
    "# i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
    "decay_params = [p for n, p in param_dict.items() if p.ndim >= 2]\n",
    "decay_param_tree = eqx.filter(gpt, lambda l: any([jnp.array_equal(l, x) for x in decay_params]), replace=False)\n",
    "decay_param_tree = eqx.filter(decay_param_tree, lambda l: l is False, replace=True)\n",
    "nodecay_params = [p for n, p in param_dict.items() if p.ndim < 2]\n",
    "\n",
    "num_decay_params = sum(jax.numpy.size(p) for p in decay_params)\n",
    "num_nodecay_params = sum(jax.numpy.size(p) for p in nodecay_params)\n",
    "print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
    "print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
    "# Create AdamW optimizer and use the fused version if it is available\n",
    "\n",
    "optimizer = optax.adamw(learning_rate=learning_rate, b1=b1, b2=b2, weight_decay=1e-1, mask=decay_param_tree)\n",
    "\n",
    "## TODO: MEKA RUN KRLA BALAPAAAAAN"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "len(decay_params), len(nodecay_params)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "for path, p in jax.tree_util.tree_flatten_with_path(gpt)[0]:\n",
    "    print(path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "for param in params:\n",
    "    print(param.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from typing import Callable\n",
    "\n",
    "def named_parameters(model: eqx.Module, is_leaf: Callable = None):\n",
    "    out = []\n",
    "\n",
    "    for path, p in jax.tree_util.tree_flatten_with_path(model, is_leaf=is_leaf)[0]:\n",
    "        if not eqx.is_array(p):\n",
    "            continue\n",
    "        pn = ''\n",
    "\n",
    "        for index in range(len(path)):\n",
    "            if isinstance(path[index], jax._src.tree_util.DictKey):\n",
    "                pn += '.' + path[index].key\n",
    "            else:\n",
    "                pn += str(path[index])\n",
    "\n",
    "        out.append((pn, p))\n",
    "    \n",
    "    return out"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "for pn, p in named_parameters(gpt):\n",
    "    print(pn, p.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def find_sub_tree(model: eqx.Module, sub_tree_name: str, filter_fn: Callable = None):\n",
    "    out = []\n",
    "    for path, p in jax.tree_util.tree_flatten_with_path(model, is_leaf=filter_fn)[0]:\n",
    "        pn = ''\n",
    "\n",
    "        for index in range(len(path)):\n",
    "            if isinstance(path[index], jax._src.tree_util.DictKey):\n",
    "                pn += '.' + path[index].key\n",
    "            else:\n",
    "                pn += str(path[index])\n",
    "\n",
    "        if filter_fn:\n",
    "            if filter_fn(p) and pn.endswith(sub_tree_name):\n",
    "                out.append(p)\n",
    "        elif pn.endswith(sub_tree_name):\n",
    "            out.append(p)\n",
    "\n",
    "    return out"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
